# -*- coding: utf-8 -*-
"""Проект: машинное обучение для текстов

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q-jbT9qviOAmHFuLepdGa-8-7O23NEUP

# Проект: машинное обучение для текстов

Интернет-магазин «...» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

**Описание проекта:** Интернет-магазин «...» внедряет функционал вики-сообщества, где пользователи могут:

редактировать описания товаров;

оставлять комментарии к правкам других пользователей.

Необходим автоматический фильтр токсичных комментариев — он поможет модераторам быстро выявлять и блокировать неподобающий контент.

**Цель:** Разработать модель машинного обучения, которая классифицирует пользовательские комментарии к товарам как токсичные или нетоксичные, чтобы автоматизировать модерацию. Модель должна иметь значение метрики F1 ≥ 0.75.

**Ход исследования:**

Шаг 1. Загрузка и изучение данных

Шаг 2. Предобработка данных и исследовательский анализ данных

Шаг 3. Подготовка данных

Шаг 4. Обучение моделей

Шаг 5. Оценка качества моделей

Шаг 6. Выводы

**Общий вывод:** резюмирование полученных результатов, формулировка ключевых выводов и рекомендаций.

С помощью данного исследования мы стремимся дать всесторонний анализ проблемы выявления токсичных комментариев в пользовательских текстах. Мы исследуем структуру данных, применим современные методы обработки естественного языка, обучим и сравним несколько моделей классификации.

## Подготовка
"""

from google.colab import files
uploaded = files.upload()

!pip install catboost

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import re
import nltk
import torch
import spacy

from nltk.corpus import stopwords
from tqdm import tqdm
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from sklearn.svm import LinearSVC

RANDOM_STATE = 42
TEST_SIZE = 0.2
VALID_SIZE = 0.25

plt.rcParams["figure.figsize"] = (7, 7)

!python -m spacy download en_core_web_sm

"""### Загрузка и изучение данных"""

data = pd.read_csv('toxic_comments.csv')

def analysis_df(data):
    data.info()
    display(data.isna().sum())
    display(data.duplicated().sum())
    display(data.head(10))
    display(data.shape)

analysis_df(data)

"""Вывод:

Размер: 159 292 строк, 3 столбца

Столбцы:

Unnamed:0 индекс

text — текст комментария

toxic — целевая переменная (0 — не токсично, 1 — токсично)

Пропусков нет

Дубликатов нет

### Предобработка данных и исследовательский анализ данных
"""

sns.countplot(x='toxic', data=data)
plt.title('Распределение классов (токсичность)')
plt.xlabel('Токсичность')
plt.ylabel('Количество');

"""Около 20 тысяч твиттов токсичные"""

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def clean(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    words = text.split()
    words = [word for word in words if word not in stop_words]
    return ' '.join(words)
tqdm.pandas()
data['text_clean'] = data['text'].progress_apply(clean)

nlp = spacy.load("en_core_web_sm")

def lemmatize_text(text):
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])

data['text_lemmatized'] = data['text'].progress_apply(lemmatize_text)

tfidf = TfidfVectorizer(max_features=25000, ngram_range=(1, 1))

"""Вывод: Векторизация TF-IDF

Удалены английские стоп-слова

Результат: каждый комментарий преобразован в числовой вектор, отражающий важность слов

### Подготовка данных
"""

X_text = data['text_clean']
y = data['toxic']

X_train_valid_text, X_test_text, y_train_valid, y_test = train_test_split(
    X_text,
    y,
    test_size=TEST_SIZE,
    random_state=RANDOM_STATE,
    stratify=y
)

X_train_text, X_valid_text, y_train, y_valid = train_test_split(
    X_train_valid_text,
    y_train_valid,
    test_size=VALID_SIZE,
    random_state=RANDOM_STATE,
    stratify=y_train_valid
)

X_train = tfidf.fit_transform(X_train_text)
X_valid = tfidf.transform(X_valid_text)
X_test  = tfidf.transform(X_test_text)

"""Данные разделены на тренировочную, тестовую и валидационную выборки. Готовы для обучения моделей.

## Обучение
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_logreg = LogisticRegression(C=10)
# model_logreg.fit(X_train, y_train)
# y_pred_logreg = model_logreg.predict(X_valid)
# 
# f1_score(y_valid, y_pred_logreg)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_rf = RandomForestClassifier(n_estimators=150, random_state=RANDOM_STATE)
# model_rf.fit(X_train, y_train)
# y_pred_rf = model_rf.predict(X_valid)
# 
# f1_score(y_valid, y_pred_rf)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_cat = CatBoostClassifier(verbose=0, random_state=RANDOM_STATE)
# model_cat.fit(X_train, y_train)
# y_pred_cat = model_cat.predict(X_valid)
# 
# f1_score(y_valid, y_pred_cat)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_svc = LinearSVC()
# model_svc.fit(X_train, y_train)
# y_pred_svc = model_svc.predict(X_valid)
# 
# f1_score(y_valid, y_pred_svc)

"""По итогам обучения моделей можно сделать вывод о том, что модели LinearSVC(), CatBoostClassifier, RandomForestClassifier дают результат > 0.75.

Для дальнейшей проверки используем лучшие результаты из представленных моделей - LinearSVC().

### Оценка качества моделей
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# y_pred_svc = model_svc.predict(X_test)
# f1_score(y_test, y_pred_svc)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# X_train_valid = tfidf.transform(X_train_valid_text)
# model_svc_final = LinearSVC()
# model_svc_final.fit(X_train_valid, y_train_valid)
# y_pred_test = model_svc_final.predict(X_test)
# f1_score(y_test, y_pred_test)

"""Среди протестированных моделей наилучший результат показала линейная модель SVC (LinearSVC). Она продемонстрировала стабильную работу и достигла значения F1-меры выше порогового значения 0.75, необходимого для решения задачи классификации токсичных комментариев. LinearSVC - оптимальный выбор для данной задачи.

## Выводы
По итогу проекта разработана модель, котоорая способна автоматически определять токсичные комментарии пользователей на платформе редактирования описаний товаров. Целевая метрика — F1-score > 0.75.

- Размер набора данных: 159 292 строк.
- Пропущенных значений и дубликатов не обнаружено.
- Целевой признак — toxic, содержит 0 (не токсично) и 1 (токсично).
- Применена очистка текстов.
- Использован TF-IDF-векторизатор для преобразования текстов в числовой формат.
- Удалены стоп-слова.
- Подготовлены данные для обучения и валидации.

---

Обучены несколько моделей:

1. **Logistic Regression**
   - F1-score = 0.77
   
2. **RandomForestClassifier**
   - F1-score = 0.75
   
3. **CatBoostClassifier**
   - F1-score = 0.75
   
4. **LinearSVC**
   - F1-score = 0.78

Лучший результат показала модель LinearSVC, которая достигла значения  на тестовых данных  F1 = 0.79, что удовлетворяет требованиям задачи.
"""