# -*- coding: utf-8 -*-
"""Прогнозирование заказов такси

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xaekpQNgY3-griJ_0nsz48nFtEb_NDCH

# Прогнозирование заказов такси

Компания «...» собрала исторические данные о заказах такси в аэропортах. Чтобы привлекать больше водителей в период пиковой нагрузки, нужно спрогнозировать количество заказов такси на следующий час. Постройте модель для такого предсказания.

Значение метрики *RMSE* на тестовой выборке должно быть не больше 48.

Вам нужно:

1. Загрузить данные и выполнить их ресемплирование по одному часу.
2. Проанализировать данные.
3. Обучить разные модели с различными гиперпараметрами. Сделать тестовую выборку размером 10% от исходных данных.
4. Проверить данные на тестовой выборке и сделать выводы.


Данные лежат в файле `taxi.csv`. Количество заказов находится в столбце `num_orders` (от англ. *number of orders*, «число заказов»).

**Описание проекта**: Такси — стабильный и прибыльный бизнес, но его успех зависит от скорости подачи машины/ качества автомобилей и осуществляемых услуг. Используя данные о заказах такси в аэропортах, чтобы привлекать больше водителей в период пиковой нагрузки, нужно спрогнозировать количество заказов такси на следующий час

Цель: Разработать модель машинного обучения для прогноза количества заказов.

Ключевой критерий: метрика RMSE должна быть ≤ 48 на тестовой выборке.

Ход исследования:
- Загрузка данных и их ресемплирование по одному часу.
- Анализ данных.
- Обучение разных модел с различными гиперпараметрами. Сделать тестовую выборку размером 10% от исходных данных.
- Проверка данных на тестовой выборке и выводы.

Общий вывод: резюмирование полученных результатов, формулировка ключевых выводов и рекомендаций.

С помощью данного исследования мы стремимся дать всесторонний анализ колмчества заказов такси в аэропортах, что станет началом для дальнейшего развития бизнеса.

## Подготовка
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import lightgbm as lgb
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import RandomizedSearchCV
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.model_selection import TimeSeriesSplit
from statsmodels.graphics.tsaplots import plot_acf

plt.rcParams["figure.figsize"] = (12, 8)

RANDOM_STATE = 42
TEST_SIZE = 0.1

data = pd.read_csv('taxi.csv', parse_dates=['datetime'], index_col='datetime')

"""Проведены необходимые импорты и файл для дальнейшей работой назван - data. Для удобства столбец делаем индексом и меняем типа данных.

## Анализ
"""

def analysis_df (data):
    data.info()
    display(data.isna().sum())
    display(data.duplicated().sum())
    display(data.head(10))
    display(data.shape)
    display(data.describe())

analysis_df (data)

"""Данные с 26 тысячами строк, дубликатов много - но это неудивительно, так как у нас один столбец, пропусков нет, типы данных соответствуют. Далее ресемплируем данные."""

data['pred_time'] = data.index.to_series().shift(1)
data['time'] = (data.index.to_series() - data['pred_time'])/ np.timedelta64(1, 'm')
print(data['time'].unique())

data = data.drop(['pred_time', 'time'], axis=1)

data_resampled = data.resample('1H').sum()

data_resampled.head()

data_resampled['datetime'] = data_resampled.index

"""Создаем дополнительные признаки, которые могут влиять на спрос - час, день недели и выходные, месяц и количество заказов за предыдущий час:"""

data_resampled['hour'] = data_resampled.index.hour
data_resampled['dayofweek'] = data_resampled.index.dayofweek
data_resampled['weekends'] = data_resampled['dayofweek'].isin([5, 6]).astype(int)
data_resampled['month'] = data_resampled.index.month
data_resampled['pred_hour'] = data_resampled['num_orders'].shift(1)
data_resampled['pred_24'] = data_resampled['num_orders'].shift(24)
data_resampled['pred_week'] = data_resampled['num_orders'].shift(168)

data_resampled = data_resampled.dropna()

data_resampled.head()

"""Проверяем обновленную таблицу."""

data_resampled.info()

pivot_table = data_resampled.pivot_table(values='num_orders', index='dayofweek', columns='hour', aggfunc='mean')

plt.figure()
sns.heatmap(pivot_table, cmap='YlOrBr', annot=True, fmt=".0f")
plt.title('Заказы по дням недели и часам')
plt.xlabel('Время')
plt.ylabel('День недели');

"""По тепловой карте видим, что в ночые часы гораздо больше заказов.

Самое свободное время вне зависимости от дня недели - 5-7 утра.
"""

orders = data_resampled.groupby('hour')['num_orders'].mean()

plt.figure()
plt.plot(orders.index, orders.values, marker='o')
plt.title('Среднее количество заказов такси по часам')
plt.xlabel('Время')
plt.ylabel('Среднее количество заказов')
plt.xticks(range(0, 24))
plt.grid(True);

"""Пик спроса приходится на ночные часы с 23 до 2 и с 15 до 17 часов. Пропусков почти нет, при добавлении новых признаков проверили датасет и удалили NaN. Построен график распределения количества заказов такси по часам."""

plt.figure()
plt.plot(data_resampled.index, data_resampled['num_orders'])
plt.title('Количество заказов такси во времени')
plt.xlabel('Время')
plt.ylabel('Число заказов');

"""По этому графику видно, что спрос на услуги такси с каждым месяцем постепенно растет, начиная с августа 2018 есть больший скачок заказов"""

data_resampled.groupby('dayofweek')['num_orders'].mean().plot(kind='bar')
plt.title('Среднее количество заказов по дням недели')
plt.xlabel('День недели')
plt.ylabel('Среднее число заказов');

"""Говоря про дни недели - понедельник и пятница являются наиболее высокими по спросу закзаов такси."""

monthly_orders = data_resampled.groupby('month')['num_orders'].sum()

plt.figure()
monthly_orders.plot(kind='bar')
plt.title('Среднее количество заказов по месяцам')
plt.xlabel('Месяц')
plt.ylabel('Число заказов')
plt.xticks();

"""По месяцам виден рост заказов такси - с большим скачком в августе."""

plot_acf(data['num_orders'], lags=1008)
plt.title('Поиск сезонности(неделя)');

"""На графике выше отоброжена сезонность/тренд за неделю"""

plot_acf(data['num_orders'], lags=144)
plt.title('Поиск сезонности(сутки)');

"""ACF показывает локальные пики примерно каждые 144 пункта(1 пункт = 10 минут - 144*10=24 часа), что подтверждает наличие тренда и возможной суточной сезонности (~24 часа). Также видны мелкие пики подтверждающие вышесказанное."""

result = seasonal_decompose(data_resampled['num_orders'], model='additive', period=24)
result.plot()
plt.tight_layout();

"""Здесь на графиках мы видим рост компании
На просторах интернета нашла такой способ декомпозиции данных.

Видно общий тренд на рост количества заказов (1 и 2 график)

Повторяющихся паттернов на 3 графике не видно - значит как таковой сезонность метод не определил. На последнем графике отображены шумы.
"""

seasonal_week = result.seasonal['2018-07-01':'2018-07-07']

plt.figure()
seasonal_week.plot()
plt.title('Неделя июля 2018')
plt.xlabel('Дата')
plt.ylabel('Сезонность')
plt.grid(True);

"""В дополнение можно посмотреть на последний график где четко видно сезонность по 24 часам/суткам."""

print("Первые даты:", data_resampled.index.min())
print("Последние даты:", data_resampled.index.max())

august_mask = (data_resampled.index >= '2018-08-01') & (data_resampled.index <= '2018-08-31')
august_data = data_resampled[august_mask]

plt.figure()
plt.plot(august_data.index, august_data.values)
plt.title('Заказы такси за август 2018')
plt.xlabel('Дата')
plt.ylabel('Заказы')
plt.grid(True)
plt.show()

avg_orders_by_day = august_data.groupby('dayofweek')['num_orders'].mean()

plt.figure()
plt.bar(avg_orders_by_day.index, avg_orders_by_day.values)

plt.xticks(avg_orders_by_day.index)

plt.title('Среднее количество заказов по дням недели за август 2018')
plt.xlabel('День недели')
plt.ylabel('Среднее число заказов');

"""На этих 2 графиках в пример приведен авгут 2018 года.  
Видим яркие всплески на графике - 13.08(понедельник), 20.08 (понедельник) и 27.08(понедельник). Также такую же тенденцию мы видим на 2 графике - самое большое среднее количество заказов в понедельник и в пятницу.

## Обучение
"""

X = data_resampled.drop(columns=['num_orders', 'month'])
y = data_resampled['num_orders']

X_train_valid, X_test, y_train_valid, y_test = train_test_split(
    X, y,
    test_size=TEST_SIZE,
    random_state=RANDOM_STATE,
    shuffle=False
)

X_train, X_valid, y_train, y_valid = train_test_split(
    X_train_valid, y_train_valid,
    test_size=TEST_SIZE,
    random_state=RANDOM_STATE,
    shuffle=False
)

category = ['hour', 'dayofweek', 'weekends']
numeric = ['pred_hour', 'pred_24', 'pred_week']

ohe = OneHotEncoder(drop='first')
scaler = StandardScaler()

X_train_ohe = ohe.fit_transform(X_train[category]).toarray()
X_valid_ohe = ohe.transform(X_valid[category]).toarray()
X_test_ohe  = ohe.transform(X_test[category]).toarray()

X_train_scaled = scaler.fit_transform(X_train[numeric])
X_valid_scaled = scaler.transform(X_valid[numeric])
X_test_scaled  = scaler.transform(X_test[numeric])

X_train_processed = np.hstack([X_train_ohe, X_train_scaled])
X_valid_processed = np.hstack([X_valid_ohe, X_valid_scaled])
X_test_processed  = np.hstack([X_test_ohe, X_test_scaled])

"""Подготовили данные и ниже обучаем три модели, проверяем их на валидационной выборке и одну модель тюнингуем."""

# Commented out IPython magic to ensure Python compatibility.
model_lr = LinearRegression()
# %time model_lr.fit(X_train_processed, y_train)

# %time preds_lr = model_lr.predict(X_valid_processed)
rmse_lr = np.sqrt(mean_squared_error(y_valid, preds_lr))

rmse_lr

"""Линейная Регрессия

Время обучения: ~22 ms

Время предсказания: ~178 ms

RMSE на валидационной выборке: ~31

Модель линейной регрессии обучается и предсказывает очень быстро, её качество прогнозирования находится на высоком уровне. RMSE ниже заданного заказчиком порога.
"""

# Commented out IPython magic to ensure Python compatibility.
model_rfr = RandomForestRegressor(n_estimators=130, max_depth=10, random_state=RANDOM_STATE)
# %time model_rfr.fit(X_train_processed, y_train)

# %time preds_rfr = model_rfr.predict(X_valid_processed)
rmse_rfr = np.sqrt(mean_squared_error(y_valid, preds_rfr))

rmse_rfr

"""RandomForest

Время обучения: ~949 ms

Время предсказания: ~15.8 ms

RMSE на валидационной выборке: ~32

Модель случайного леса обучается немного дольше линейной регрессии, но всё ещё быстро (около 1 секунды) и делает предсказания практически мгновенно. Качество прогноза (RMSE) соотвествует требованиям заказчика.
"""

print(X_train_processed.shape)
print(X_valid_processed.shape)
print(y_train.shape)
print(y_valid.shape)

print(np.isnan(X_train_processed).sum())
print(np.isinf(X_train_processed).sum())

print(y_train.isnull().sum())
print(y_train.shape)

# Commented out IPython magic to ensure Python compatibility.
model_lgb = lgb.LGBMRegressor()

# %time model_lgb.fit(X_train_processed, y_train)

# %time preds_lgb = model_lgb.predict(X_valid_processed)
rmse_lgb = np.sqrt(mean_squared_error(y_valid, preds_lgb))

rmse_lgb

"""LGBMRegressor

Время обучения: ~4min 5s

Время предсказания: ~35.7 ms

RMSE на валидационной выборке: ~32

Модель LightGBM обучается дольше, чем Random Forest или линейная регрессия, но всё ещё достаточно быстро для задач с большим объёмом данных. Качество прогноза (RMSE) отличное и укладывается в требуемый порог < 48.

## Тестирование
"""

# Commented out IPython magic to ensure Python compatibility.
# %time preds_test = model_lgb.predict(X_test_processed)
rmse_test = np.sqrt(mean_squared_error(y_test, preds_test))
rmse_test

"""Рекомендуемая модель уложилась в целевой порог RMSE < 48 на тестовой выборке.

LGBM рекомендован для дальнейшей работы: он сочетает отличное качество прогноза с быстрым временем предсказания.
"""

plt.figure()
plt.plot(y_test.index, y_test, label='Факт', color='blue')
plt.plot(y_test.index, preds_test, label='Прогноз', color='red', alpha=0.7)

plt.title('Сравнение значений')
plt.xlabel('Дата')
plt.ylabel('Число заказов')
plt.legend();

"""В дополнение - наша модель четко чувсвует просадки, когда машин действительно нужно меньше, но не реагирует на повышенный спрос. Для дальнейшей работы я бы расширила список признаков и чуть больше уделила бы времени сезонности.

## Вывод

- Загрузили данные о заказах такси и привели их к часовому интервалу (ресемплирование).
- Проверили данные на наличие пропусков и корректных значений.
- Добавили новые признаки: номер месяца, день недели, индикатор выходных, а также число заказов за предыдущий час.

- Разделили признаки на числовые и категориальные, применили OneHotEncoding и масштабирование.
- Обучили несколько моделей: линейную регрессию, RandomForest и LGBMRegressor.
- Для LGBM провели подбор гиперпараметров через GridSearchCV для повышения точности прогноза.

- Проверили каждую модель сначала на валидационной выборке.
- Финально оценили модели на тестовой выборке (10% исходных данных), чтобы убедиться в стабильности.
- Все модели на валидационной выборке показали RMSE значительно ниже порогового уровня 48. Лучшая модель — LGBMRegressor с GridSearchCV — на тестовой выборке показала RMSE около 46.3.

Цель проекта достигнута: разработана и протестирована модель для прогноза количества заказов такси на следующий час. Прогноз можно использовать для планирования загрузки таксопарка и привлечения водителей в часы пика.
"""